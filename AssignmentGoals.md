Goals
Tokenizer
    Read input file line by line and convert the textual inputinto an ordered collection of tokens and lexemes

Reconizer
    use recursive decent to parse the output of the tokenizer and determine if the given tokens form a valid program.


Common.java (Optional)
    define any and all 
        includes/imports, contants, globals, enums, structs/objects which are shared between the
        Tokenizer.* and the Reconizer.*
    Define Token Enum
        each enum is one of the distict token classes defined in the provided lexical structure
    Each lexeme generated by Tokenizer will have a corresponding token class.
        Create class to enforce that association (Lex)
            two data fields, one lexeme and one for associcated token class

Tokenizer.java
    Take in two arguments
        filepath of the input file
        filepath of the output file
    Each file will be 256 characters or less
    Iterate over characters and determine the lexem class
        alphanumeric, whitespace, symbol
    Dont use split functions
    Some lexems are multiple characters 
        ex: if, void

    Anywords accepted by the regex are apart of that class
        Except specific words in the tokens
            return is the RETURN_KEYWORD token not the IDENTIFIER token
        Check if the lexeme is a reserved word before assigning IDENTIFIER token
    
        
Reconizer.java
